import pandas as pd
from bertopic import BERTopic
from sklearn.feature_extraction.text import CountVectorizer
import os

# ğŸ“ ì„¤ì •
input_path = "C:/Users/0120c/BERT_PROJECT/data_file/stock_30k_full_predictions.csv"
output_dir = "topic_full"
os.makedirs(output_dir, exist_ok=True)

# ğŸ“Œ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
df = pd.read_csv(input_path, encoding="cp949", encoding_errors="ignore")
docs = df["sentence"].dropna().drop_duplicates().tolist()
print(f"âœ… ì „ì²´ ë¬¸ì¥ ìˆ˜: {len(docs)}")

# ğŸ“Œ CountVectorizer ì„¤ì •
vectorizer_model = CountVectorizer(stop_words="english", max_df=0.95, min_df=10)

# ğŸ“Œ BERTopic ëª¨ë¸ ìƒì„±
topic_model = BERTopic(
    vectorizer_model=vectorizer_model,
    language="english",
    calculate_probabilities=False,
    verbose=True
)

# ğŸ“Œ í† í”½ ëª¨ë¸ë§ ì‹¤í–‰
topics, probs = topic_model.fit_transform(docs)

# ğŸ“ ë¬¸ì¥ë³„ ê²°ê³¼ ì €ì¥
df_result = pd.DataFrame({"sentence": docs, "topic": topics})
df_result.to_csv(f"{output_dir}/topic_full_data.csv", index=False, encoding="utf-8-sig")

# ğŸ“Š í† í”½ ì •ë³´ ìš”ì•½ ì €ì¥
topic_info = topic_model.get_topic_info()
topic_info.to_csv(f"{output_dir}/topic_summary.csv", index=False, encoding="utf-8-sig")

# ğŸ“ ì •ì„± ë¶„ì„: í† í”½ë³„ ëŒ€í‘œ ë¬¸ì¥ 2ê°œì”© ì¶”ì¶œ
examples = []
for topic_num in topic_info["Topic"]:
    if topic_num == -1:
        continue  # -1ì€ outlier í† í”½ â†’ ì œì™¸
    example_docs = df_result[df_result["topic"] == topic_num].head(2)["sentence"].tolist()
    keywords_only = [word for word, _ in topic_model.get_topic(topic_num)]  # âœ… ì—¬ê¸°ë§Œ ìˆ˜ì •
    for i, sent in enumerate(example_docs):
        examples.append({
            "topic": topic_num,
            "rank": i + 1,
            "keywords": keywords_only,
            "example_sentence": sent
        })
example_df = pd.DataFrame(examples)
example_df.to_csv(f"{output_dir}/topic_examples.csv", index=False, encoding="utf-8-sig")

# ğŸ“Š ì‹œê°í™” ì €ì¥
topic_model.visualize_barchart(top_n_topics=10).write_html(f"{output_dir}/top10_barchart.html")
topic_model.visualize_topics().write_html(f"{output_dir}/topic_clusters.html")
topic_model.visualize_heatmap().write_html(f"{output_dir}/topic_heatmap.html")

print("ğŸ‰ ì „ì²´ ë¬¸ì¥ í† í”½ëª¨ë¸ë§ + ì •ì„±ë¶„ì„ ì™„ë£Œ!")
print(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_dir}")
